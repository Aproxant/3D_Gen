{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import trimesh\n",
    "from functools import partial\n",
    "import ssl\n",
    "from Solvers import SolverEmbedding,Loss\n",
    "from Models.EncoderModels import TextEncoder, ShapeEncoder\n",
    "from config import cfg\n",
    "from dataEmbedding.dataEmbedding import Read_Load_BuildBatch\n",
    "from dataEmbedding.dataEmbeddingLoader import GenerateDataLoader,check_dataset,collate_embedding\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device=torch.device(\"cuda\")\n",
    "else:\n",
    "    device=torch.device(\"cpu\")\n",
    "\n",
    "device=cfg.DEVICE\n",
    "print(device)\n",
    "PYTORCH_ENABLE_MPS_FALLBACK=1\n",
    "#for mac os fix \n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#primiData = Read_Load_BuildBatch('/primitives',batchSize,'primitives')\n",
    "stanData=Read_Load_BuildBatch(cfg.EMBEDDING_VOXEL_FOLDER,cfg.EMBEDDING_BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of list is : 14.0\n",
      "Mean: 16.307937873199133\n"
     ]
    }
   ],
   "source": [
    "stanData.wordlens.sort()\n",
    "mid = len(stanData.wordlens) // 2\n",
    "res = (stanData.wordlens[mid] + stanData.wordlens[~mid]) / 2\n",
    "print(\"Median of list is : \" + str(res))\n",
    "print(\"Mean: \"+ str(sum(stanData.wordlens)/len(stanData.wordlens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GenerateDataLoader(stanData.data_agg_train,stanData.data_dir,stanData.dict_word2idx)\n",
    "\n",
    "val_dataset = GenerateDataLoader(stanData.data_agg_val,stanData.data_dir,stanData.dict_word2idx)\n",
    "\n",
    "test_dataset=GenerateDataLoader(stanData.data_agg_test,stanData.data_dir,stanData.dict_word2idx)\n",
    "\n",
    "dataloader = {\n",
    "            'train': DataLoader(\n",
    "                train_dataset, \n",
    "                batch_size=cfg.EMBEDDING_BATCH_SIZE * 2,              \n",
    "                drop_last=check_dataset(train_dataset, cfg.EMBEDDING_BATCH_SIZE * 2),\n",
    "                collate_fn=collate_embedding,\n",
    "                num_workers=4\n",
    "            ),\n",
    "            'val': DataLoader(\n",
    "                val_dataset, \n",
    "                batch_size=cfg.EMBEDDING_BATCH_SIZE*2,\n",
    "                collate_fn=collate_embedding,\n",
    "                num_workers=4\n",
    "            ),\n",
    "            'test': DataLoader(\n",
    "                test_dataset, \n",
    "                batch_size=cfg.EMBEDDING_BATCH_SIZE*2,\n",
    "                collate_fn=collate_embedding\n",
    "                #num_workers=2\n",
    "            )\n",
    "    }       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[141,  38, 134,  ...,   9, 363,   4],\n",
      "        [ 35, 141,  48,  ...,   0,   0,   0],\n",
      "        [387,   3,  17,  ...,  10,   0,   0],\n",
      "        ...,\n",
      "        [  2,   3,   4,  ..., 285,  83,  10],\n",
      "        [ 48,  21,  38,  ...,   0,   0,   0],\n",
      "        [  2,   3,   4,  ...,  37,  35, 217]], device='mps:0')\n",
      "tensor([[  35,  190,   17,  ..., 1822,   88,   12],\n",
      "        [  48,   21,  482,  ...,    0,    0,    0],\n",
      "        [ 106,  125,   21,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [  18,    4,  572,  ..., 1245,   17,  285],\n",
      "        [  35,   12,   17,  ...,    0,    0,    0],\n",
      "        [ 181,   30,  493,  ...,    0,    0,    0]], device='mps:0')\n",
      "tensor([[ 12,  13,  14,  ...,   0,   0,   0],\n",
      "        [ 35, 239,  34,  ...,  14,   2,  12],\n",
      "        [ 18, 318,  35,  ...,   9,   0,   0],\n",
      "        ...,\n",
      "        [ 35,   5, 108,  ...,   0,   0,   0],\n",
      "        [ 82,  83, 101,  ...,  10,   0,   0],\n",
      "        [ 48,  21,  82,  ...,  37,  73,   9]], device='mps:0')\n",
      "tensor([[ 120,   48,   38,  ...,    0,    0,    0],\n",
      "        [  35,   48,   38,  ...,    0,    0,    0],\n",
      "        [  35,   19,  141,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [  18,    4,   34,  ...,   10,    0,    0],\n",
      "        [  35,  840,   38,  ...,   17,   52, 1497],\n",
      "        [  35,  130,   48,  ...,   64,    4,   93]], device='mps:0')\n",
      "tensor([[ 18,   4,  93,  ..., 482,  10,   0],\n",
      "        [175, 554,  12,  ...,   0,   0,   0],\n",
      "        [ 34, 172,  37,  ..., 366,  37,  19],\n",
      "        ...,\n",
      "        [ 35,   3,  37,  ...,   0,   0,   0],\n",
      "        [ 35,  12,  13,  ...,  88, 103,   6],\n",
      "        [ 19, 121,  12,  ...,  71,  30,   5]], device='mps:0')\n",
      "tensor([[  35,  161,  172,  ...,  366,   33,    2],\n",
      "        [  35,  285,   83,  ...,   70,    4,  115],\n",
      "        [ 175,  114,  244,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [  35,  861,   12,  ...,    2,   39,    4],\n",
      "        [ 277,    4, 2864,  ...,    0,    0,    0],\n",
      "        [  35,   34,  126,  ...,    0,    0,    0]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "for iter,(_,labels,texts,_,shapes) in enumerate(dataloader['train']):\n",
    "    if cfg.EMBEDDING_SHAPE_ENCODER:\n",
    "\n",
    "        batch_size = shapes.size(0)\n",
    "    texts = texts.to(device)\n",
    "    text_labels = labels.to(device)\n",
    "    \n",
    "    if cfg.EMBEDDING_SHAPE_ENCODER:\n",
    "\n",
    "        shapes = shapes.to(device).index_select(0, torch.LongTensor([i * 2 for i in range(batch_size // 2)]).to(device))\n",
    "        shape_labels = labels.to(device).index_select(0, torch.LongTensor([i * 2 for i in range(batch_size // 2)]).to(device))\n",
    "        \n",
    "\n",
    "    #s = ShapeModel(shapes)\n",
    "    \n",
    "    print(texts)\n",
    "    #print(texts.shape)\n",
    "\n",
    "    if iter==5:\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion={\n",
    "        'walker': Loss.RoundTripLoss(device=device),\n",
    "        'visit': Loss.AssociationLoss(device=device),\n",
    "        #'metric': Loss.SmoothedMetricLoss(device=device)\n",
    "        #'metric': Loss.InstanceMetricLoss()\n",
    "        'metric': Loss.TripletLoss()\n",
    "        'metric':Loss.NPairLoss()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ShapeModel=ShapeEncoder()\n",
    "ShapeModel=ShapeModel.to(device)\n",
    "TextModel=TextEncoder(len(stanData.dict_word2idx))\n",
    "TextModel=TextModel.to(device)\n",
    "optimizer = torch.optim.Adam(list(ShapeModel.parameters()) + list(TextModel.parameters()), lr=cfg.EMBEDDING_LR, weight_decay=cfg.EMBEDDING_WEIGHT_DC)\n",
    "history=SolverEmbedding.Solver(TextModel,ShapeModel,dataloader,optimizer,criterion,cfg.EMBEDDING_BATCH_SIZE,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.train(cfg.EMBEDDING_EPOCH_NR,stanData.dict_idx2word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
